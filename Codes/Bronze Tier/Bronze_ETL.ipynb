{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5abdba",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaabcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eda stacks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import s3fs\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#display settings\n",
    "pd.set_option(\"display.max_columns\", 200)      # show all columns\n",
    "pd.set_option(\"display.max_rows\", 20)         # show more rows\n",
    "pd.set_option(\"display.width\", 1200)           # wider output\n",
    "pd.set_option(\"display.max_colwidth\", 100)     # long text columns\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)  # clean decimals\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214653d",
   "metadata": {},
   "source": [
    "# Function to flatten JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2364f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_param(params, key):\n",
    "    if params is None:\n",
    "        return None\n",
    "\n",
    "    # handle list OR numpy array\n",
    "    if isinstance(params, (list, np.ndarray)):\n",
    "        for p in params:\n",
    "            if p.get(\"key\") == key:\n",
    "                val = p.get(\"value\", {})\n",
    "                return (\n",
    "                    val.get(\"string_value\")\n",
    "                    or val.get(\"int_value\")\n",
    "                    or val.get(\"float_value\")\n",
    "                    or val.get(\"double_value\")\n",
    "                )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890c509",
   "metadata": {},
   "source": [
    "# Function to Transform (Bronze Tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bronze_transform(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    #identifiers\n",
    "    identifiers=df.sort_values(by=['date_ist','user_id','session_id'],ascending=[True,True,True])\n",
    "    identifiers=identifiers.drop_duplicates(subset=['date_ist','user_id','session_id'])[['date_ist','user_id','session_id','page_location','page_type','device']]\n",
    "    identifiers.rename(columns={'page_location':'landing_page','page_type':'landing_page_type'},inplace=True)\n",
    "    #dimensions\n",
    "    start = df.loc[df[\"event\"] == \"session_start\"].copy()\n",
    "    start[\"source\"] = start[\"event_params\"].apply(\n",
    "    lambda x: get_event_param(x, \"source\"))\n",
    "    start[\"medium\"] = start[\"event_params\"].apply(\n",
    "    lambda x: get_event_param(x, \"medium\"))\n",
    "    start[\"campaign\"] = start[\"event_params\"].apply(\n",
    "    lambda x: get_event_param(x, \"campaign\"))\n",
    "    dimensions=identifiers.merge(start[['source','medium','campaign','user_id','session_id']],how='left',on=['user_id','session_id'])\n",
    "    #funnel\n",
    "    events=['add_shipping_info', 'add_payment_info', 'purchase','view_item','view_product_page_loaded','add_to_cart','add_to_cart_custom_event','begin_checkout','gokwik_checkout_initiated']\n",
    "    focus=df[df['event'].isin(events)]\n",
    "    focus['event']=np.where(focus['event'].isin(['view_item','view_product_page_loaded']),'product_view',focus['event'])\n",
    "    focus['event']=np.where(focus['event'].isin(['add_to_cart','add_to_cart_custom_event']),'add_to_cart',focus['event'])\n",
    "    focus['event']=np.where(focus['event'].isin(['begin_checkout','gokwik_checkout_initiated']),'begin_checkout',focus['event'])\n",
    "    funnel=focus.groupby(['user_id','session_id','event']).agg(\n",
    "    first_timestamp=('time_ist','min')).reset_index()\n",
    "    #cartesian product\n",
    "    users = funnel[['user_id','session_id']].drop_duplicates()\n",
    "    events=pd.DataFrame(\n",
    "    {\"event\":funnel['event'].unique()})\n",
    "    users=users.merge(events,how='cross')\n",
    "    #beautifying funnel\n",
    "    funnel_new=users.merge(funnel,how='left',on=['user_id','session_id','event'])\n",
    "    funnel_new.fillna(0,inplace=True)\n",
    "    funnel_new['flag']=np.where(funnel_new['first_timestamp']==0,0,1)\n",
    "    #purchases\n",
    "    purchases=df.loc[df[\"event\"] == \"purchase\"].copy()\n",
    "    purchases[\"transaction_id\"] = purchases[\"event_params\"].apply(\n",
    "    lambda x: get_event_param(x, \"transaction_id\"))\n",
    "    purchases[\"value\"] = purchases[\"event_params\"].apply(\n",
    "    lambda x: get_event_param(x, \"value\"))\n",
    "    purchases=purchases[['user_id','session_id','time_ist','transaction_id','value']]\n",
    "    purchases=purchases.groupby(['user_id','session_id']).agg(\n",
    "    orders=('transaction_id','nunique'),\n",
    "    orders_dups_inclusive=('transaction_id','count'),\n",
    "    rev=('value','sum')).reset_index()\n",
    "    purchases['aov']=purchases['rev']/purchases['orders']\n",
    "    #final merging and nesting\n",
    "    final=dimensions.copy()\n",
    "    cols_to_nest = [\n",
    "    \"landing_page\",\n",
    "    \"landing_page_type\",\n",
    "    \"source\",\n",
    "    \"medium\",\n",
    "    \"campaign\",\n",
    "    \"device\"]\n",
    "    final[\"dimensions\"] = final[cols_to_nest].to_dict(orient=\"records\")\n",
    "    final = final.drop(columns=cols_to_nest)\n",
    "    funnel_event_cols=[\"event\", \"flag\", \"first_timestamp\"]\n",
    "    funnel_new[\"event_payload\"] = funnel_new.apply(\n",
    "    lambda r: {\n",
    "        r[\"event\"]: {\n",
    "            \"flag\": r[\"flag\"],\n",
    "            \"first_timestamp\": r[\"first_timestamp\"]\n",
    "        }\n",
    "    },\n",
    "    axis=1)\n",
    "    funnel_df = (\n",
    "    funnel_new\n",
    "    .groupby([\"user_id\", \"session_id\"], as_index=False)\n",
    "    .agg({\n",
    "        \"event_payload\": lambda x: {\n",
    "            k: v\n",
    "            for d in x\n",
    "            for k, v in d.items()\n",
    "        }\n",
    "    })\n",
    "    .rename(columns={\"event_payload\": \"funnels\"}))\n",
    "    final=final.merge(funnel_df,how='inner',on=['user_id','session_id'])\n",
    "    final=final.merge(purchases,how='left',on=['user_id','session_id'])\n",
    "    final.fillna(0,inplace=True)\n",
    "    cols_to_nest = [\n",
    "    \"orders\",\n",
    "    \"orders_dups_inclusive\",\n",
    "    \"rev\",\n",
    "    \"aov\"]\n",
    "    final[\"purchase\"] = final[cols_to_nest].to_dict(orient=\"records\")\n",
    "    final = final.drop(columns=cols_to_nest)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6916ed",
   "metadata": {},
   "source": [
    "# Transforming all Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9db58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=\"kerala-ayurveda-s3\"\n",
    "prefix=\"raw-data/\"\n",
    "\n",
    "fs=s3fs.S3FileSystem()\n",
    "dfs=[]\n",
    "\n",
    "for i in range(0, 32):\n",
    "    file_key=f\"{prefix}events_{i:012d}.parquet\"\n",
    "    s3_path=f\"s3://{bucket}/{file_key}\"\n",
    "    \n",
    "    print(f\"Reading {s3_path}\")\n",
    "    df=pd.read_parquet(s3_path, filesystem=fs)\n",
    "    print(f\"{file_key} was of shape: {df.shape}\")\n",
    "    df=bronze_transform(df)\n",
    "    dfs.append(df)\n",
    "    print(f\"{file_key} transformed to shape: {df.shape}\")\n",
    "    for k in range(0,11):\n",
    "        print(\"*\")\n",
    "df=pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Final df's shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=df.sort_values(by='date_ist',ascending=True).date_ist.unique() #QA\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3313268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429effc9",
   "metadata": {},
   "source": [
    "# Saving in the S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42819e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"bronze-tier/\"\n",
    "s3_path=f\"s3://{bucket}/{prefix}bronze_data.csv\"\n",
    "df.to_csv(\n",
    "    s3_path,\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
